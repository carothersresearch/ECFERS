{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "rxns = pd.read_csv('/workspaces/ECFERS/src/frenda_brenda/Files/KEGG_Filtered/Reactions_M3_plusCustom.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Retrieve coordinates from KEGG\n",
    "### 1a. Get the (x,y) coordinates for each species in the KEGG map -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "orthology_ids = {'R00315': ['K00925'],\n",
    " 'R01353': ['K00925', 'K00932', 'K19697'],\n",
    " 'R00235': ['K01895', 'K01913'],\n",
    " 'R00236': ['K01895', 'K01913'],\n",
    " 'R00316': ['K01895', 'K01913'],\n",
    " 'R00925': ['K01895', 'K01908'],\n",
    " 'R00742': ['K01946',\n",
    "  'K01961',\n",
    "  'K01962',\n",
    "  'K01963',\n",
    "  'K01964',\n",
    "  'K02160',\n",
    "  'K11262',\n",
    "  'K11263',\n",
    "  'K15036',\n",
    "  'K15037',\n",
    "  'K18472',\n",
    "  'K18603',\n",
    "  'K18604',\n",
    "  'K18605',\n",
    "  'K19312',\n",
    "  'K22568'],\n",
    " 'R01324': ['K01681', 'K01682', 'K27802'],\n",
    " 'R01325': ['K01681', 'K01682', 'K27802'],\n",
    " 'R01900': ['K01681', 'K01682', 'K27802'],\n",
    " 'R00754': ['K00001',\n",
    "  'K00121',\n",
    "  'K04022',\n",
    "  'K04072',\n",
    "  'K13951',\n",
    "  'K13952',\n",
    "  'K13953',\n",
    "  'K13954',\n",
    "  'K13980',\n",
    "  'K18857'],\n",
    " 'R02124': ['K00001',\n",
    "  'K00121',\n",
    "  'K11149',\n",
    "  'K11154',\n",
    "  'K13369',\n",
    "  'K13951',\n",
    "  'K13952',\n",
    "  'K13953',\n",
    "  'K13980',\n",
    "  'K15734'],\n",
    " 'R04880': ['K00001',\n",
    "  'K00121',\n",
    "  'K04072',\n",
    "  'K13951',\n",
    "  'K13952',\n",
    "  'K13953',\n",
    "  'K13954',\n",
    "  'K13980',\n",
    "  'K18857'],\n",
    " 'R05233': ['K00001', 'K00121', 'K04072', 'K13953', 'K13954'],\n",
    " 'R05234': ['K00001', 'K00121', 'K04072', 'K13953', 'K13954'],\n",
    " 'R08557': ['K11440'],\n",
    " 'R08558': ['K11440'],\n",
    " 'R00746': ['K00002', 'K12957', 'K13979'],\n",
    " 'R00352': ['K01648', 'K15230', 'K15231'],\n",
    " 'R00351': ['K01647', 'K01659', 'K05942', 'K27797'],\n",
    " 'R03815': ['K00382'],\n",
    " 'R07618': ['K00382'],\n",
    " 'R00209': ['K00161', 'K00162', 'K00163', 'K00382', 'K00627'],\n",
    " 'R01221': ['K00281', 'K00282', 'K00283', 'K00382', 'K00605', 'K02437'],\n",
    " 'R01933': ['K00382', 'K00658', 'K15791'],\n",
    " 'R08549': ['K00164', 'K00382', 'K00658', 'K01616'],\n",
    " 'R00704': ['K03777', 'K03778'],\n",
    " 'R01082': ['K01675', 'K01676', 'K01677', 'K01678', 'K01679', 'K01774'],\n",
    " 'R01736': ['K01069'],\n",
    " 'R00267': ['K00031'],\n",
    " 'R00268': ['K00031'],\n",
    " 'R01899': ['K00031'],\n",
    " 'R00342': ['K00024', 'K00025', 'K00026'],\n",
    " 'R00214': ['K00027', 'K00028'],\n",
    " 'R00217': ['K01003'],\n",
    " 'R00216': ['K00029'],\n",
    " 'R00230': ['K00625', 'K04020', 'K13788', 'K15024'],\n",
    " 'R00921': ['K00625', 'K13788', 'K13923', 'K15024'],\n",
    " 'R00341': ['K01610'],\n",
    " 'R00345': ['K01595'],\n",
    " 'R00200': ['K00873', 'K12406'],\n",
    " 'R01138': ['K00873', 'K12406'],\n",
    " 'R01858': ['K00873', 'K12406'],\n",
    " 'R02320': ['K00873', 'K12406'],\n",
    " 'R00199': ['K01007'],\n",
    " 'R02164': ['K00233',\n",
    "  'K00234',\n",
    "  'K00235',\n",
    "  'K00236',\n",
    "  'K00237',\n",
    "  'K00239',\n",
    "  'K00240',\n",
    "  'K00241',\n",
    "  'K00242',\n",
    "  'K00244',\n",
    "  'K00245',\n",
    "  'K00246',\n",
    "  'K00247',\n",
    "  'K18859',\n",
    "  'K18860',\n",
    "  'K25801',\n",
    "  'K25995',\n",
    "  'K25996'],\n",
    " 'R00405': ['K01902', 'K01903'],\n",
    " 'R02404': ['K01902', 'K01903'],\n",
    " 'R00220': ['K01752', 'K01754', 'K17989'],\n",
    " 'R00519': ['K00122', 'K00123', 'K00124', 'K00126', 'K00127', 'K22515'],\n",
    " 'R00344': ['K01958', 'K01959', 'K01960'],\n",
    " 'R00226': ['K01652', 'K01653', 'K11258'],\n",
    " 'R08648': ['K01652', 'K01653', 'K11258'],\n",
    " 'R00945': ['K00600'],\n",
    " 'R09099': ['K00600'],\n",
    " 'R00497': ['K01920', 'K21456'],\n",
    " 'R00371': ['K00639'],\n",
    " 'R03425': ['K00281', 'K00282', 'K00283'],\n",
    " 'R00479': ['K01637']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "from Bio.KEGG.KGML import KGML_parser\n",
    "from Bio.Graphics.KGML_vis import KGMLCanvas\n",
    "\n",
    "def map_reaction_to_entry_id(xml_file_path, reaction_orthology_dict):\n",
    "    # Parse the XML file\n",
    "    pathway = KGML_parser.read(open(xml_file_path, 'r'))\n",
    "\n",
    "    # Initialize dictionary to hold the reaction ID -> entry ID mapping\n",
    "    reaction_entry_map = {}\n",
    "\n",
    "    # Loop through each entry in the pathway\n",
    "    for entry in pathway.entries.values():\n",
    "        # Check if the entry is of type 'ortholog'\n",
    "        if entry.type == \"ortholog\":\n",
    "            # Extract the orthology IDs (split by space, remove 'ko:' prefix)\n",
    "            orthology_ids_in_entry = entry.name.replace('ko:', '').split()\n",
    "\n",
    "            # Convert to set for comparison\n",
    "            orthology_ids_in_entry_set = set(orthology_ids_in_entry)\n",
    "\n",
    "            # Loop through the reaction dictionary\n",
    "            for reaction_id, orthology_ids in reaction_orthology_dict.items():\n",
    "                if len(orthology_ids)==0:\n",
    "                    continue\n",
    "                # Convert orthology_ids from the reaction dictionary to a set\n",
    "                orthology_ids_set = set(orthology_ids)\n",
    "\n",
    "                # Check if all orthology IDs in the entry are present in orthology_ids_set\n",
    "                # CHANGING THIS AS AN EXPERIMENT: CHECK IF ANY OF THE ORTHOLOGY IDS IN THE ENTRY ARE PRESENT IN ORTHOLOGY_IDS_SET\n",
    "                # if not orthology_ids_set.isdisjoint(orthology_ids_in_entry_set):\n",
    "                # if orthology_ids_set.issubset(orthology_ids_in_entry_set):\n",
    "                if not orthology_ids_set.isdisjoint(orthology_ids_in_entry_set):\n",
    "                    # Add the mapping to the dictionary\n",
    "                    if reaction_id not in reaction_entry_map:\n",
    "                        reaction_entry_map[reaction_id] = []\n",
    "                    reaction_entry_map[reaction_id].append(entry.id)  # Save the entry ID\n",
    "\n",
    "    return reaction_entry_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_file = '/workspaces/ECFERS/ko01100.xml'\n",
    "reaction_entry_map = map_reaction_to_entry_id(xml_file, orthology_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathway = KGML_parser.read(open(xml_file, 'r'))\n",
    "reaction_dict = reaction_entry_map\n",
    "    \n",
    "# Initialize dictionary to hold the cpd ID and Reaction ID mapping\n",
    "cpd_coordinates_map = {}\n",
    "\n",
    "# Loop through the reaction dictionary\n",
    "for reaction_id, entry_ids in reaction_dict.items():\n",
    "    for entry_id in entry_ids:\n",
    "        # Search for the reaction in the pathway\n",
    "        reaction_entry = next((reaction for reaction in pathway.reactions if reaction.id == entry_id), None)\n",
    "\n",
    "        if reaction_entry:\n",
    "            newrns = []\n",
    "            for rn in reaction_entry._names:\n",
    "                newrns.append(rn.replace('rn:',''))\n",
    "            if reaction_id in newrns:\n",
    "                # Collect substrates\n",
    "                sloop_counter = 0\n",
    "                for substrate in reaction_entry._substrates:\n",
    "                    substrate_entry = next((sub for sub in pathway.entries.values() if sub.id == substrate), None)\n",
    "                    x, y = substrate_entry.graphics[0].x, substrate_entry.graphics[0].y\n",
    "                    \n",
    "                    rxnentry = str(reaction_entry)\n",
    "                    # Split the string into lines and find the line containing 'Substrates'\n",
    "                    substrates_line = next(line for line in rxnentry.splitlines() if 'Substrates:' in line)\n",
    "                    # Extract the part of the line after 'Substrates:'\n",
    "                    substrates_part = substrates_line.split('Substrates: ')[1]\n",
    "                    # Split the substrates by comma and strip the 'cpd:' prefix\n",
    "                    cpd_id = [substrate.strip().replace('cpd:', '') for substrate in substrates_part.split(',')][sloop_counter]\n",
    "                    sloop_counter += 1\n",
    "\n",
    "                    cpd_coordinates_map[f\"{cpd_id}_{reaction_id}_{entry_id}\"] = (x, y)\n",
    "\n",
    "                # Collect products\n",
    "                ploop_counter = 0\n",
    "                for product in reaction_entry._products:\n",
    "                    product_entry = next((prod for prod in pathway.entries.values() if prod.id == product), None)\n",
    "                    x, y = product_entry.graphics[0].x, product_entry.graphics[0].y\n",
    "                    \n",
    "                    rxnentry = str(reaction_entry)\n",
    "                    # Split the string into lines and find the line containing 'Substrates'\n",
    "                    products_line = next(line for line in rxnentry.splitlines() if 'Products:' in line)\n",
    "                    # Extract the part of the line after 'Substrates:'\n",
    "                    products_part = products_line.split('Products: ')[1]\n",
    "                    # Split the substrates by comma and strip the 'cpd:' prefix\n",
    "                    cpd_id = [product.strip().replace('cpd:', '') for product in products_part.split(',')][ploop_counter]\n",
    "                    ploop_counter += 1\n",
    "\n",
    "                    cpd_coordinates_map[f\"{cpd_id}_{reaction_id}_{entry_id}\"] = (x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/workspaces/ECFERS/kegg_labels_add.csv',dtype='str',encoding='us-ascii',encoding_errors='ignore')\n",
    "data = data.where(data.notnull(), None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new dictionary with replaced keys\n",
    "cpd_coordinates_map_tran = {}\n",
    "for key, value in cpd_coordinates_map.items():\n",
    "    new_key = key\n",
    "    # Check for each \"KEGG ID\" in the key string\n",
    "    for _, row in data.iterrows():\n",
    "        kegg_id = row['KEGG ID']\n",
    "        id_value = row['ID']\n",
    "        # Replace any occurrence of the \"KEGG ID\" within the key string\n",
    "        if kegg_id in new_key:\n",
    "            new_key = new_key.replace(kegg_id, id_value)\n",
    "    # Add the modified key-value pair to the new dictionary\n",
    "    cpd_coordinates_map_tran[new_key] = value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Apply KEGG coordinates to SBMLNetwork layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tellurium as te\n",
    "import sbmlnetwork\n",
    "\n",
    "r = te.loada('/workspaces/ECFERS/src/frenda_brenda/Files/KEGG_Filtered/M3a_renamed.txt')\n",
    "net = sbmlnetwork.load(r.getSBML())\n",
    "\n",
    "# net = sbmlnetwork.load('/workspaces/ECFERS/src/frenda_brenda/Files/KEGG_Filtered/M3_renamed_fin.sbml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.auto_layout(max_num_connected_edges=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/workspaces/ECFERS/src/frenda_brenda/Files/KEGG_Filtered/Reactions_M3_plusCustom.csv')\n",
    "\n",
    "net_reactions = net.get_reactions_list()\n",
    "\n",
    "label_to_reaction_id = dict(zip(df['Label'], df['Reaction ID']))\n",
    "M3_reaction_labels = net.get_reaction_ids()\n",
    "M3_reactionIDs = [label_to_reaction_id.get(item, item) for item in M3_reaction_labels]\n",
    "\n",
    "# label_to_ID_dict = {}\n",
    "# i = 0\n",
    "# for label in M3_reaction_labels:\n",
    "#     label_to_ID_dict[label] = M3_reactionIDs[i]\n",
    "#     i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_ID_dict = {}\n",
    "i = 0\n",
    "for net_reaction in net_reactions:\n",
    "    label_to_ID_dict[net_reaction.get_reaction_id()] = {'id': M3_reactionIDs[i], 'reaction_object': net_reaction}\n",
    "    i = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translate label_to_reaction_id dictionary\n",
    "reaction_id_to_label = {v: k for k, v in label_to_reaction_id.items()}\n",
    "\n",
    "# Process cpd_coordinates_map_tran to update reaction labels\n",
    "translated_cpd_coordinates = {}\n",
    "for key, coords in cpd_coordinates_map_tran.items():\n",
    "    species, reaction, entry_id = key.rsplit(\"_\", 2)\n",
    "    reaction_label = reaction_id_to_label.get(reaction, reaction)  # Translate if possible\n",
    "    size = net.get_species(species).get_size()\n",
    "    updatedcoords = (coords[0]-(size[0]/2), coords[1]-(size[1]/2))\n",
    "\n",
    "    translated_cpd_coordinates[(species, reaction_label, entry_id)] = updatedcoords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Organize species mapping\n",
    "species_mapping = {}\n",
    "for (species, reaction, entry_id), coords in translated_cpd_coordinates.items():\n",
    "    species_mapping.setdefault(species, {}).setdefault(reaction, {})[entry_id] = coords\n",
    "\n",
    "# Organize species mapping\n",
    "reaction_mapping = {}\n",
    "for (species, reaction, entry_id), coords in translated_cpd_coordinates.items():\n",
    "    reaction_mapping.setdefault(reaction, {}).setdefault(species, {})[entry_id] = coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "entry_mapping = {}\n",
    "\n",
    "for species, reaction, entry_id in translated_cpd_coordinates.keys():\n",
    "    if entry_id not in entry_mapping:\n",
    "        entry_mapping[entry_id] = {}\n",
    "    if reaction not in entry_mapping[entry_id]:\n",
    "        entry_mapping[entry_id][reaction] = []\n",
    "    entry_mapping[entry_id][reaction].append(species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Species(id=Pyr, index=0)\n",
      "{'R346': {'1556': (2369.0, 1695.0)}, 'R406': {'4482': (2369.0, 1695.0)}, 'R347': {'3083': (2369.0, 1695.0)}, 'R350': {'3083': (2369.0, 1695.0)}, 'R181': {'1304': (2369.0, 1695.0)}, 'R62': {'2209': (2369.0, 1695.0)}, 'R63': {'2205': (2369.0, 1695.0)}, 'R270': {'2409': (2079.0, 3087.0)}, 'R272': {'2409': (2079.0, 3087.0)}, 'R273': {'3008': (2369.0, 1695.0)}, 'R345': {'3008': (2369.0, 1695.0)}, 'R351': {'3083': (2369.0, 1695.0)}}\n"
     ]
    }
   ],
   "source": [
    "specieslist = net.get_species_list()\n",
    "\n",
    "# Dictionary to store already set coordinates and their aliases\n",
    "set_coordinates = {}\n",
    "reaction_aliases = {}\n",
    "\n",
    "multipleentryids = []\n",
    "special_metabs = []\n",
    "\n",
    "for spc in specieslist:\n",
    "    try:\n",
    "        allcoords = species_mapping[spc.get_species_id()]\n",
    "    except KeyError:\n",
    "        spc.hide()\n",
    "        continue\n",
    "\n",
    "    # Extract all coordinate values\n",
    "    coordinates = {coord for subdict in allcoords.values() for coord in subdict.values()}\n",
    "\n",
    "    # Check if all coordinates are the same\n",
    "    all_same = len(coordinates) == 1\n",
    "\n",
    "    if all_same:  # SETTING COORDINATES FOR ALL SPECIES WHICH ONLY HAVE ONE POSITION\n",
    "        coordinate = next(iter(coordinates))\n",
    "        if coordinate not in set_coordinates:\n",
    "            spc.set_position(coordinate)\n",
    "            set_coordinates[coordinate] = spc.get_species_id()  # Store the species ID associated with the coordinate\n",
    "        else:\n",
    "            # Species has already been set for this coordinate, no further action needed\n",
    "            pass\n",
    "    else:  # appears in more than one position, will need to make an alias\n",
    "        special_metabs.append(spc.get_species_id())\n",
    "\n",
    "        multiple_entries = False\n",
    "\n",
    "        for reaction, entry_coords in allcoords.items():\n",
    "            if len(entry_coords) > 1:\n",
    "                multiple_entries = True\n",
    "\n",
    "        if len(allcoords) == 1:\n",
    "            # this means there is only one reaction, but >1 entry ID for that reaction. need to make an alias for the REACTION here\n",
    "            multipleentryids.append(reaction)\n",
    "        else:\n",
    "            # multiple reactions\n",
    "            if multiple_entries:\n",
    "                # at least one of the reactions contains >1 entry ID\n",
    "                multipleentryids.append(reaction)\n",
    "            else:\n",
    "                print(spc)\n",
    "                print(allcoords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicatereactions = []\n",
    "for rxn in multipleentryids:\n",
    "    for v in reaction_mapping[rxn].values():\n",
    "        if(len(v)) > 1:\n",
    "            duplicatereactions.append(rxn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicatereactions = list(set(duplicatereactions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for metabolite, entry_coords in reaction_mapping['R64'].items():\n",
    "    entry_ids = list(entry_coords.keys())  # Get keys as a list\n",
    "\n",
    "id_index_assignments = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hiding Species(id=ATP, index=0)\n",
      "hiding Species(id=CO2, index=0)\n",
      "hiding Species(id=eEC6412, index=0)\n",
      "hiding Species(id=ADP, index=0)\n",
      "hiding Species(id=PO4, index=0)\n",
      "hiding Species(id=ATP, index=1)\n",
      "hiding Species(id=CO2, index=1)\n",
      "hiding Species(id=eEC6412, index=1)\n",
      "hiding Species(id=ADP, index=1)\n",
      "hiding Species(id=PO4, index=1)\n"
     ]
    }
   ],
   "source": [
    "# making alias reactions and setting coordinates for R64\n",
    "\n",
    "for spc in net.get_reaction('R64').get_species_list():\n",
    "    if spc.get_species_id() in reaction_mapping['R64'].keys():\n",
    "        # print(f'setting position of {spc} with entry ID {entry_ids[0]} to {reaction_mapping['R64'][spc.get_species_id()][entry_ids[0]]}')\n",
    "        spc.set_position(reaction_mapping['R64'][spc.get_species_id()][entry_ids[0]])\n",
    "        id_index_assignments[entry_ids[0]] = 0\n",
    "    else:\n",
    "        print(f'hiding {spc}')\n",
    "        spc.hide()\n",
    "\n",
    "aliasreaction = net.get_reaction('R64').create_alias()\n",
    "\n",
    "for spc in aliasreaction.get_species_list():\n",
    "    if spc.get_species_id() in reaction_mapping['R64'].keys():\n",
    "        if spc.get_species_id() == 'AcCoA':\n",
    "            aliasreaction.assign_species(net.get_species_list('AcCoA')[0])\n",
    "        else:\n",
    "            # print(f'setting position of {spc} with entry ID {entry_ids[1]} to {reaction_mapping['R64'][spc.get_species_id()][entry_ids[1]]}')\n",
    "            spc.set_position(reaction_mapping['R64'][spc.get_species_id()][entry_ids[1]])\n",
    "            id_index_assignments[entry_ids[1]] = 1\n",
    "    else:\n",
    "        print(f'hiding {spc}')\n",
    "        spc.hide()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SETTING REACTION 227\n",
    "net.get_reactions_list('R227').get_species_list()[0].hide()\n",
    "net.get_reactions_list('R227').get_species_list()[1].set_position(reaction_mapping['R227']['Glycine']['7890']) # 7890 is the entry ID for index = 0 reaction\n",
    "net.get_reactions_list('R227').get_species_list()[2].set_position(reaction_mapping['R227']['_510CH2THF']['7890'])\n",
    "net.get_reactions_list('R227').get_species_list()[3].hide()\n",
    "net.get_reactions_list('R227').get_species_list()[4].set_position(reaction_mapping['R227']['Serine']['7890'])\n",
    "net.get_reactions_list('R227').get_species_list()[5].set_position(reaction_mapping['R227']['THF']['7890'])\n",
    "\n",
    "alias227 = net.get_reactions_list('R227').create_alias()\n",
    "\n",
    "alias227[0].assign_species(net.get_reactions_list('R227').get_species_list()[0])\n",
    "# alias227.get_species_list()[0].hide()\n",
    "alias227.get_species_list()[1].hide() # 5411 is the entry ID for index = 0 reaction\n",
    "alias227.get_species_list()[2].set_position(reaction_mapping['R227']['_510CH2THF']['5411'])\n",
    "alias227.get_species_list()[3].hide()\n",
    "alias227.get_species_list()[4].hide()\n",
    "alias227.get_species_list()[5].set_position(reaction_mapping['R227']['THF']['5411'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.get_reactions_list('R269').get_species_list()\n",
    "\n",
    "alias_H = net.get_species(\"H\").create_alias(net.get_reactions_list('R269')[0])\n",
    "alias_H.hide()\n",
    "net.get_reactions_list('R269').get_species_list()[0].hide() # NAD\n",
    "net.get_reactions_list('R269').get_species_list()[1].set_position(reaction_mapping['R269']['Mal']['4357']) # 4357 is the entry ID for index = 0 reaction\n",
    "net.get_reactions_list('R269').get_species_list()[2].hide() # enzyme\n",
    "net.get_reactions_list('R269').get_species_list()[3].hide() # NADH\n",
    "net.get_reactions_list('R269').get_species_list()[4].set_position(reaction_mapping['R269']['Oxa']['4357'])\n",
    "# net.get_reactions_list('R269').get_species_list()[4].hide()\n",
    "net.get_reactions_list('R269')[0].assign_species(alias_H)\n",
    "\n",
    "alias269 = net.get_reactions_list('R269').create_alias()\n",
    "\n",
    "alias269.get_species_list()[0].hide()\n",
    "alias269.get_species_list()[1].set_position(reaction_mapping['R269']['Mal']['5622']) # 5622 is the entry ID for index = 1 reaction\n",
    "alias269.get_species_list()[2].hide()\n",
    "alias269.get_species_list()[3].hide()\n",
    "alias269.get_species_list()[4].set_position(reaction_mapping['R269']['Oxa']['5622'])\n",
    "# alias269.get_species_list()[4].hide()\n",
    "alias269[0].assign_species(alias_H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.get_reactions_list('R308').get_species_list()\n",
    "\n",
    "# for entry ID 3007\n",
    "net.get_reactions_list('R308').get_species_list()[0].hide() # PO4\n",
    "net.get_reactions_list('R308')[0].assign_species(net.get_reactions_list('R269').get_species_list()[4])\n",
    "# net.get_reactions_list('R308').get_species_list()[1].set_position(reaction_mapping['R308']['Oxa']['4357']) # assign this reaction to have Oxa set earlier\n",
    "net.get_reactions_list('R308').get_species_list()[2].hide() # enzyme\n",
    "net.get_reactions_list('R308').get_species_list()[3].hide() # H2O\n",
    "net.get_reactions_list('R308').get_species_list()[4].hide()\n",
    "net.get_reactions_list('R308').get_species_list()[5].set_position(reaction_mapping['R308']['PEP']['3007'])\n",
    "\n",
    "alias308 = net.get_reactions_list('R308').create_alias()\n",
    "\n",
    "# for entry ID 2412\n",
    "alias308.get_species_list()[0].hide()\n",
    "alias308[0].assign_species(alias269.get_species_list()[4])\n",
    "# alias308.get_species_list()[1].set_position(reaction_mapping['R269']['Mal']['5622']) # 5622 is the entry ID for index = 1 reaction\n",
    "alias308.get_species_list()[2].hide()\n",
    "alias308.get_species_list()[3].hide()\n",
    "alias308[0].assign_species(net.get_reactions_list('R308').get_species_list()[2])\n",
    "alias308.get_species_list()[4].set_position(reaction_mapping['R308']['CO2']['2412'])\n",
    "alias308.get_species_list()[5].set_position(reaction_mapping['R308']['PEP']['2412'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.get_reactions_list('R307').get_species_list()[0].hide()\n",
    "net.get_reactions_list('R307')[0].assign_species(net.get_reactions_list('R269').get_species_list()[4])\n",
    "# net.get_reactions_list('R307').get_species_list()[1].set_position(reaction_mapping['R307']['Oxa']['4357']) # assign this reaction to have Oxa set earlier\n",
    "net.get_reactions_list('R307').get_species_list()[2].hide()\n",
    "net.get_reactions_list('R307').get_species_list()[3].hide()\n",
    "net.get_reactions_list('R307').get_species_list()[4].hide()\n",
    "net.get_reactions_list('R307')[0].assign_species(net.get_reactions_list('R308').get_species_list()[5])\n",
    "# net.get_reactions_list('R307').get_species_list()[4].set_position(reaction_mapping['R307']['PEP']['4357'])\n",
    "\n",
    "alias307 = net.get_reactions_list('R307').create_alias()\n",
    "\n",
    "alias307.get_species_list()[0].hide()\n",
    "alias307[0].assign_species(alias269.get_species_list()[4])\n",
    "# alias307.get_species_list()[1].set_position(reaction_mapping['R269']['Mal']['5622']) # 5622 is the entry ID for index = 1 reaction\n",
    "alias307.get_species_list()[2].hide()\n",
    "alias307.get_species_list()[3].hide()\n",
    "alias307.get_species_list()[4].hide()\n",
    "alias307[0].assign_species(alias308.get_species_list()[5])\n",
    "# alias307.get_species_list()[4].set_position(reaction_mapping['R269']['Oxa']['5622'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.get_species('Pyr').set_position(reaction_mapping['R346']['Pyr']['1556'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setting for Pyr\n",
    "j1_reaction = net.get_reaction(\"R270\")\n",
    "alias_species = net.get_species(\"Pyr\").create_alias(j1_reaction)\n",
    "alias_species.set_position(reaction_mapping['R270']['Pyr']['2409'])\n",
    "\n",
    "j2_reaction = net.get_reaction(\"R272\")\n",
    "j2_reaction.assign_species(alias_species)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set fluxes before setting reaction curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net.show_fluxes(60*60)\n",
    "# net.fluxes.set_colors([\"#AA0000\", \"#FFCCCC\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping biosynthetic modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathway_dict = {\n",
    "    'Glycolysis / Gluconeogenesis': [\n",
    "        'R347', 'R348', 'R349', 'R350',  # Pyruvate kinase\n",
    "        'R351',  # Pyruvate, water dikinase\n",
    "        'R307'   # Phosphoenolpyruvate carboxykinase (atp)\n",
    "    ],\n",
    "    'TCA Cycle': [\n",
    "        'R157',  # Citrate synthase\n",
    "        'R69', 'R70', 'R71',  # Aconitate hydratase\n",
    "        'R255', 'R256', 'R257',  # Isocitrate dehydrogenase (nadp+)\n",
    "        'R258',  # Isocitrate lyase\n",
    "        'R299', 'R300',  # Oxoglutarate dehydrogenase (succinyl-transferring)\n",
    "        'R268', 'R269',  # Malate dehydrogenase\n",
    "        'R270', 'R271', 'R272', 'R273',  # Malate dehydrogenase (oxaloacetate-decarboxylating)\n",
    "        'R204',  # Fumarate hydratase\n",
    "        'R371',  # Succinate dehydrogenase\n",
    "        'R372', 'R373'  # Succinate-coa ligase (adp-forming)\n",
    "    ],\n",
    "    'Pyruvate Metabolism & Acetyl-CoA Formation': [\n",
    "        'R346',  # Pyruvate dehydrogenase (acetyl-transferring)\n",
    "        'R345',  # Pyruvate carboxylase\n",
    "        'R56', 'R57',  # Acetate kinase\n",
    "        'R58', 'R59', 'R60', 'R61',  # Acetate-coa ligase\n",
    "        'R64',  # Acetyl-coa carboxylase\n",
    "        'R304', 'R305'  # Phosphate acetyltransferase\n",
    "    ],\n",
    "    'Redox & Energy Metabolism': [\n",
    "        'R83', 'R84', 'R85', 'R86', 'R87', 'R88', 'R89',  # Alcohol dehydrogenase\n",
    "        'R90',  # Alcohol dehydrogenase (nadp+)\n",
    "        'R181',  # D-lactate dehydrogenase\n",
    "        'R197',  # Formate dehydrogenase\n",
    "        'R169', 'R170', 'R171', 'R172', 'R173', 'R174',  # Dihydrolipoyl dehydrogenase\n",
    "        'R175',  # Dihydrolipoyllysine-residue acetyltransferase\n",
    "        'R176', 'R177'  # Dihydrolipoyllysine-residue succinyltransferase\n",
    "    ],\n",
    "    'Amino Acid Metabolism': [\n",
    "        'R406',  # L-serine ammonia-lyase\n",
    "        'R62', 'R63',  # Acetolactate synthase\n",
    "        'R227', 'R228',  # Glycine hydroxymethyltransferase\n",
    "        'R224',  # Glycine c-acetyltransferase\n",
    "        'R225'  # Glycine dehydrogenase (aminomethyl-transferring)\n",
    "    ],\n",
    "    'Cofactor & Detoxification Pathways': [\n",
    "        'R245',  # Hydroxyacylglutathione hydrolase\n",
    "        'R219'  # Glutathione synthase\n",
    "    ],\n",
    "    'Anaplerotic & Carbon Fixation Pathways': [\n",
    "        'R123',  # Atp citrate synthase\n",
    "        'R308'  # Phosphoenolpyruvate carboxylase\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# colors = ['red', 'blue', 'orange', 'yellow', 'green', 'grey', 'purple']\n",
    "# for i, mod in enumerate(pathway_dict.keys()):\n",
    "#     net.group_reactions(pathway_dict[mod], colors[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting reaction curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio.KEGG.KGML import KGML_parser\n",
    "\n",
    "xml_file_path = '/workspaces/ECFERS/ko01100.xml'\n",
    "pathway = KGML_parser.read(open(xml_file_path, 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True,\n",
       " True]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.get_reactions_list().hide()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Organize species mapping\n",
    "reaction_mapping = {}\n",
    "for (species, reaction, entry_id), coords in translated_cpd_coordinates.items():\n",
    "    reaction_mapping.setdefault(reaction, {}).setdefault(entry_id, {})[species] = coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_species(entry_mapping, entry_id):\n",
    "    species = set()  # Use a set to avoid duplicates\n",
    "    if entry_id in entry_mapping:\n",
    "        for reaction in entry_mapping[entry_id].values():\n",
    "            species.update(reaction)  # Add species from each reaction\n",
    "    return list(species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_coordinates(entry_mapping, species_mapping, entry_id):\n",
    "    species_list = get_species(entry_mapping, entry_id)  # Get species for entry ID\n",
    "    coordinates = []  # Use a list to maintain order\n",
    "    seen = set()  # Track unique coordinates\n",
    "    \n",
    "    for species in species_list:\n",
    "        if species in species_mapping:\n",
    "            for reaction_data in species_mapping[species].values():\n",
    "                if entry_id in reaction_data:  # Check if entry ID exists in reaction data\n",
    "                    coord = reaction_data[entry_id]\n",
    "                    if coord not in seen:  # Ensure uniqueness while maintaining order\n",
    "                        coordinates.append(coord)\n",
    "                        seen.add(coord)\n",
    "    \n",
    "    return coordinates, species_list  # Return ordered list of unique coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import euclidean\n",
    "\n",
    "def find_curve_origin(involved_species_coords, starting_point):\n",
    "    # Compute distances\n",
    "    distances = [euclidean(starting_point, p) for p in involved_species_coords]\n",
    "\n",
    "    # Find the closest point\n",
    "    closest_point = distances.index(min(distances))\n",
    "\n",
    "    return closest_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "for reaction in reaction_mapping.keys():\n",
    "    for i, entry_id in enumerate(reaction_mapping[reaction]):\n",
    "\n",
    "        for graphicsid in range(len(pathway.entries[int(entry_id)].graphics)):\n",
    "\n",
    "            linecoords = pathway.entries[int(entry_id)].graphics[graphicsid].coords\n",
    "\n",
    "            rxn = net.get_reactions_list(reaction)[i]\n",
    "\n",
    "            rxn.set_position(([(linecoords[0][0] + linecoords[-1][0]) / 2, \n",
    "                                    (linecoords[0][1] + linecoords[-1][1]) / 2]))\n",
    "            \n",
    "            first_point = linecoords[0]\n",
    "            last_point = linecoords[-1]\n",
    "\n",
    "            involved_species_coords = get_unique_coordinates(entry_mapping, species_mapping, entry_id)\n",
    "\n",
    "            starting_index = find_curve_origin(involved_species_coords[0], first_point)\n",
    "            ending_index = find_curve_origin(involved_species_coords[0], last_point)\n",
    "\n",
    "            if len(linecoords) == 2:\n",
    "                middle_point = ([(linecoords[0][0] + linecoords[-1][0]) / 2, \n",
    "                                    (linecoords[0][1] + linecoords[-1][1]) / 2])\n",
    "            else:\n",
    "                middle_point = linecoords[int(len(linecoords)/2)]\n",
    "\n",
    "            for j, k in enumerate([starting_index, ending_index]):\n",
    "                curve = rxn.get_curves_list(rxn.get_species(involved_species_coords[1][k])[0])[0]\n",
    "\n",
    "                curve.show()\n",
    "\n",
    "                terminate = False  # Flag to stop processing further coordinates\n",
    "                current_index = 0\n",
    "\n",
    "                # Precompute coverage regions for all involved species coordinates\n",
    "                coverage_regions = [\n",
    "                    (coord[0] - 18, coord[0] + 18, coord[1] - 18, coord[1] + 18) \n",
    "                    for coord in involved_species_coords[0]\n",
    "                ]\n",
    "\n",
    "                if j == 1:\n",
    "                    linecoords.reverse()\n",
    "\n",
    "                for j in range(len(linecoords) - 1):\n",
    "                    if terminate:\n",
    "                        break\n",
    "\n",
    "                    line_start, line_end = linecoords[j], linecoords[j + 1]\n",
    "\n",
    "                    if linecoords[j] == middle_point:\n",
    "                        break\n",
    "\n",
    "                    for x_min, x_max, y_min, y_max in coverage_regions:\n",
    "                        # Check if line_end is inside a coverage region, but line_start is not\n",
    "                        if ((x_min <= line_end[0] <= x_max and y_min <= line_end[1] <= y_max) and\n",
    "                            not (x_min < line_start[0] < x_max and y_min < line_start[1] < y_max)):\n",
    "\n",
    "                            # If the last point is not inside any coverage region, add a segment\n",
    "                            if not any(x_min <= linecoords[-1][0] <= x_max and y_min <= linecoords[-1][1] <= y_max \n",
    "                                    for x_min, x_max, y_min, y_max in coverage_regions):\n",
    "                                \n",
    "                                curve.add_segment(line_start, line_end, line_start, line_end)\n",
    "                                break  # Stop checking once a segment is added\n",
    "\n",
    "                            # Adjust the segment endpoint to stay within coverage bounds\n",
    "                            adjusted_x, adjusted_y = line_end\n",
    "                            if line_start[0] < x_min or line_start[0] > x_max:\n",
    "                                adjusted_x = x_max if line_start[0] >= x_max else x_min\n",
    "                            if line_start[1] < y_min or line_start[1] > y_max:\n",
    "                                adjusted_y = y_min if line_start[1] <= y_min else y_max\n",
    "\n",
    "                            # Remove the first segment if needed\n",
    "                            if current_index == 0:\n",
    "                                curve.remove_segment(0)\n",
    "\n",
    "                            # Add the adjusted segment\n",
    "                            curve.add_segment(line_start, (adjusted_x, adjusted_y), line_start, (adjusted_x, adjusted_y))\n",
    "                            terminate = True\n",
    "                            break  # Stop checking once a segment is added\n",
    "\n",
    "                    if not terminate:\n",
    "                        if current_index == 0:\n",
    "                            curve_segment = curve.get_segment(current_index)\n",
    "                            curve_segment.set_start(line_start)\n",
    "                            curve_segment.set_end(line_end)\n",
    "                            curve_segment.set_control_point_1(line_start)\n",
    "                            curve_segment.set_control_point_2(line_end)\n",
    "\n",
    "                            curve.add_segment(line_start, line_end, line_start, line_end)\n",
    "                        else:\n",
    "                            curve.add_segment(line_start, line_end, line_start, line_end)\n",
    "\n",
    "                    current_index += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True, True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True],\n",
       " [True]]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "species = net.get_species_list()\n",
    "\n",
    "for s in species:\n",
    "    s.set_shape('circle')\n",
    "    spcname = s.get_species_id()\n",
    "    for _, row in data.iterrows():\n",
    "        label = row['Label']\n",
    "        id_value = row['ID']\n",
    "        # Replace any occurrence of the \"KEGG ID\" within the key string\n",
    "        if spcname == id_value:\n",
    "            s.set_text(label)\n",
    "species.move_texts_by((30, 30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.draw('/workspaces/ECFERS/example_v3.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net.save('/workspaces/ECFERS/example_v3.xml')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
