{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "os.chdir('..')\n",
    "s = requests.Session() # create session\n",
    "# Post login credentials to session:\n",
    "s.post('https://websvc.biocyc.org/credentials/login/', data={'email':'diegoalbaburbano@gmail.com', 'password':'qwerty'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from EC to BioCyc Reaction ID\n",
    "EC = '2.3.3.16'\n",
    "r = s.get('https://metacyc.org/META/substring-search?type=NIL&object=EC+'+EC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc = r.text.find('/reaction?orgid=META&id=') # this only finds the first instance, there may be other reactinos associated with this EC...\n",
    "BioCycID = r.text[loc+len('/reaction?orgid=META&id='):].split('\"')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MALATE-DEH-RXN'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BioCycID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from BioCyc Reaction ID to  reactions\n",
    "r = s.get('https://websvc.biocyc.org/apixml?fn=enzymes-of-reaction&id=META:{i}&detail=low'.format(i=BioCycID))\n",
    "reactions = [e.find('catalyzes').find('Enzymatic-Reaction').items()[0][1] for e in list(ET.fromstring(r.text))[1:]]\n",
    "\n",
    "# from reactions to inhibitors\n",
    "inhibitors = []\n",
    "inhibitors_smiles = []\n",
    "for reaction in reactions:\n",
    "    r = s.get('https://websvc.biocyc.org/apixml?fn=direct-inhibitors&id={i}&detail=low'.format(i=reaction))\n",
    "    inhibitors.append([list(c)[-1].text for c in list(ET.fromstring(r.text))[1:]])\n",
    "    inhibitors_smiles.append([c.find('cml')[0][-1].text for c in list(ET.fromstring(r.text))[1:]])\n",
    "\n",
    "inhibitors = sum(inhibitors,[])\n",
    "inhibitors_smiles = sum(inhibitors_smiles,[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CCCCCCCCCCCCCCCC(SCCNC(=O)CCNC(=O)[C@H](O)C(C)(C)COP(=O)(OP(=O)(OC[C@@H]1([C@@H](OP([O-])(=O)[O-])[C@@H](O)[C@@H](O1)N2(C3(\\\\N=C/N=C(C(\\\\N=C/2)=3)/N))))[O-])[O-])=O',\n",
       " 'C(O)[C@H]3(O[C@@H](N1(C2(\\\\C(\\\\N=C/1)=C(N)/N=C\\\\N=2)))[C@H](O)[C@H](OP([O-])(=O)[O-])3)',\n",
       " 'C(CC([O-])=O)C(=O)C([O-])=O',\n",
       " 'CCC(=O)SCCNC(=O)CCNC(=O)[C@H](O)C(C)(C)COP(=O)(OP(=O)(OC[C@@H]1([C@@H](OP([O-])(=O)[O-])[C@@H](O)[C@@H](O1)N2(C3(\\\\N=C/N=C(C(\\\\N=C/2)=3)/N))))[O-])[O-]',\n",
       " 'CC(C)([C@@H](O)C(=O)NCCC(=O)NCCSCC([O-])=O)COP(=O)(OP(=O)(OC[C@H]1(O[C@H]([C@@H]([C@@H]1OP([O-])(=O)[O-])O)N2(C3(\\\\N=C/N=C(C(\\\\N=C/2)=3)/N))))[O-])[O-]',\n",
       " 'C1(/N(\\\\C=C/CC(/C(N)=O)=1)[C@@H]5(O[C@H](COP(OP(OC[C@H]4(O[C@@H](N2(C3(\\\\C(\\\\N=C/2)=C(N)/N=C\\\\N=3)))[C@H](O)[C@H](O)4))(=O)[O-])(=O)[O-])[C@@H](O)[C@@H](O)5))']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inhibitors_smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "from equilibrator_api import ComponentContribution\n",
    "cc = ComponentContribution()\n",
    "\n",
    "inhibitors_kegg = []\n",
    "for inhibitor in inhibitors:\n",
    "    try: # the inhibitor string may be too off, or has no kegg id\n",
    "        for i in cc.search_compound(inhibitor).identifiers:\n",
    "            if i.registry.namespace == 'kegg':\n",
    "                inhibitors_kegg.append(i.accession)\n",
    "    except:\n",
    "        inhibitors_kegg.append('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C00036',\n",
       " 'C00002',\n",
       " 'D08646',\n",
       " 'C00024',\n",
       " 'C00010',\n",
       " 'C00209',\n",
       " 'C02441',\n",
       " 'C11592',\n",
       " 'C00741',\n",
       " '']"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inhibitors_kegg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let put in a function and run thorugh all ECs\n",
    "\n",
    "def get_inhibitors(s, EC, output = 'SMILES'):\n",
    "    try:\n",
    "        with open(os.getcwd()+'/src/kinetic_estimator/biocyc_cache.pickle', 'rb') as handle:\n",
    "            biocyc_cache = pickle.load(handle)\n",
    "    except:\n",
    "        biocyc_cache = {}\n",
    "    \n",
    "    if EC+'_'+output in biocyc_cache:\n",
    "        return biocyc_cache[EC+'_'+output]\n",
    "    \n",
    "    else:\n",
    "        r = s.get('https://metacyc.org/META/substring-search?type=NIL&object=EC+'+EC)\n",
    "        # old version\n",
    "        # loc = r.text.find('/META/NEW-IMAGE?type=REACTION&object=') # this only finds the first instance, there may be other reactinos associated with this EC...\n",
    "        # BioCycID = r.text[loc+37:].split('\"')[0]\n",
    "        loc = r.text.find('/reaction?orgid=META&id=') # this only finds the first instance, there may be other reactinos associated with this EC...\n",
    "        BioCycID = r.text[loc+len('/reaction?orgid=META&id='):].split('\"')[0]\n",
    "        print(BioCycID)\n",
    "\n",
    "        try:\n",
    "            # from BioCyc Reaction ID to  reactions\n",
    "            r = s.get('https://websvc.biocyc.org/apixml?fn=enzymes-of-reaction&id=META:{i}&detail=low'.format(i=BioCycID))\n",
    "            if r.status_code != 200:\n",
    "                print('No reaction found for EC '+EC)\n",
    "                return []\n",
    "            reactions = [e.find('catalyzes').find('Enzymatic-Reaction').items()[0][1] for e in list(ET.fromstring(r.text))[1:]]\n",
    "        except:\n",
    "            with open('src/kinetic_estimator/xmls/'+BioCycID+'.xml', 'r') as handle:\n",
    "                r = handle.read()\n",
    "                reactions = [e.find('catalyzes').find('Enzymatic-Reaction').items()[0][1] for e in list(ET.fromstring(r))[1:]]\n",
    "\n",
    "        # print(reactions)\n",
    "        # from reactions to inhibitors\n",
    "        inhibitors = []\n",
    "        inhibitors_smiles = []\n",
    "        for reaction in reactions:\n",
    "            r = s.get('https://websvc.biocyc.org/apixml?fn=direct-inhibitors&id={i}&detail=low'.format(i=reaction))\n",
    "            inhibitors.append([list(c)[-1].text for c in list(ET.fromstring(r.text))[1:] if c ])\n",
    "            inhibitors_smiles.append([c.find('cml')[0][-1].text for c in list(ET.fromstring(r.text))[1:] if c and c.find('cml')])\n",
    "\n",
    "        inhibitors = sum(inhibitors,[])\n",
    "        inhibitors_smiles = sum(inhibitors_smiles,[])\n",
    "        biocyc_cache[EC+'_SMILES'] = inhibitors_smiles\n",
    "        biocyc_cache[EC+'_names'] = inhibitors\n",
    "        with open(os.getcwd()+'/src/kinetic_estimator/biocyc_cache.pickle', 'wb') as handle:\n",
    "            pickle.dump(biocyc_cache, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "        if output == 'kegg':\n",
    "            from equilibrator_api import ComponentContribution\n",
    "            cc = ComponentContribution()\n",
    "            inhibitors_kegg = []\n",
    "            for inhibitor in inhibitors:\n",
    "                try: # the inhibitor string may be too off, or has no kegg id\n",
    "                    for i in cc.search_compound(inhibitor).identifiers:\n",
    "                        if i.registry.namespace == 'kegg':\n",
    "                            inhibitors_kegg.append(i.accession)\n",
    "                except:\n",
    "                    print(\"Didn't find kegg id for \"+inhibitor)\n",
    "                    # inhibitors_kegg.append('')\n",
    "                    pass\n",
    "            biocyc_cache[EC+'_kegg'] = inhibitors_kegg\n",
    "            with open(os.getcwd()+'/src/kinetic_estimator/biocyc_cache.pickle', 'wb') as handle:\n",
    "                pickle.dump(biocyc_cache, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "            return inhibitors_kegg\n",
    "        \n",
    "        elif output == 'SMILES':\n",
    "            return inhibitors_smiles\n",
    "        elif output == 'names':\n",
    "            return inhibitors\n",
    "        else:\n",
    "            return inhibitors, inhibitors_smiles\n",
    "    \n",
    "# get all EC numbers\n",
    "import gzip\n",
    "import json\n",
    "\n",
    "with gzip.open(\"src/thermo_calculations/kegg_enzymes.json.gz\", \"r\") as f:\n",
    "        ECs = {e['EC']:e['reaction_ids'] for e in json.load(f)}\n",
    "\n",
    "with gzip.open(\"src/thermo_calculations/kegg_reactions.json.gz\", \"r\") as f:\n",
    "        RXNs = {r['RID']:r['reaction'] for r in json.load(f)}\n",
    "\n",
    "# reactions = pd.read_csv('src/frenda_brenda/Files/Reaction_full.csv')\n",
    "# all_enzymes = []\n",
    "# all_organisms = []\n",
    "# for i,row in reactions.iterrows():\n",
    "#     ec_string = row['EC']\n",
    "#     try:\n",
    "#         for r in ECs[ec_string]:\n",
    "#             try:\n",
    "#                 if ec_string not in all_enzymes:\n",
    "#                     all_enzymes.append(ec_string)\n",
    "#                     if type(row['Species']) is str:\n",
    "#                         organism = r['Species']\n",
    "#                     else:\n",
    "#                         organism = 'Escherichia coli' \n",
    "#                     all_organisms.append(organism)\n",
    "#             except:\n",
    "#                 pass\n",
    "#     except:\n",
    "#         pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "reactions = pd.read_csv('src/frenda_brenda/Files/KEGG_Filtered/Reactions_M8.csv')\n",
    "reactions = reactions.iloc[[288, 88, 115]]\n",
    "all_enzymes = reactions['EC'].values\n",
    "all_organisms = reactions['Species'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2.1.2-RXN\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'content-md5'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m all_inhibitors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43me\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_inhibitors\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mkegg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_enzymes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# flatten lists\u001b[39;00m\n\u001b[1;32m      4\u001b[0m all_enzymes \u001b[38;5;241m=\u001b[39m [[enzyme]\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlen\u001b[39m(inhibitors) \u001b[38;5;28;01mfor\u001b[39;00m enzyme, inhibitors \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(all_enzymes, all_inhibitors)]\n",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(e)\u001b[0m\n\u001b[0;32m----> 1\u001b[0m all_inhibitors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28;01mlambda\u001b[39;00m e: \u001b[43mget_inhibitors\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mkegg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m, all_enzymes))\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# flatten lists\u001b[39;00m\n\u001b[1;32m      4\u001b[0m all_enzymes \u001b[38;5;241m=\u001b[39m [[enzyme]\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlen\u001b[39m(inhibitors) \u001b[38;5;28;01mfor\u001b[39;00m enzyme, inhibitors \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(all_enzymes, all_inhibitors)]\n",
      "Cell \u001b[0;32mIn[7], line 52\u001b[0m, in \u001b[0;36mget_inhibitors\u001b[0;34m(s, EC, output)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkegg\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mequilibrator_api\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ComponentContribution\n\u001b[0;32m---> 52\u001b[0m     cc \u001b[38;5;241m=\u001b[39m \u001b[43mComponentContribution\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m     inhibitors_kegg \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m inhibitor \u001b[38;5;129;01min\u001b[39;00m inhibitors:\n",
      "File \u001b[0;32m/opt/conda/envs/myenv/lib/python3.9/site-packages/equilibrator_api/component_contribution.py:148\u001b[0m, in \u001b[0;36mComponentContribution.__init__\u001b[0;34m(self, rmse_inf, ccache, predictor)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m rmse_inf \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m rmse_inf\u001b[38;5;241m.\u001b[39mcheck(\n\u001b[1;32m    145\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[energy]/[substance]\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    146\u001b[0m     ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrmse_inf must be in units of kJ/mol (or equivalent)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 148\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mccache \u001b[38;5;241m=\u001b[39m ccache \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mcreate_compound_cache_from_zenodo\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m predictor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    151\u001b[0m     parameters \u001b[38;5;241m=\u001b[39m CCModelParameters\u001b[38;5;241m.\u001b[39mfrom_zenodo()\n",
      "File \u001b[0;32m/opt/conda/envs/myenv/lib/python3.9/site-packages/equilibrator_cache/api.py:73\u001b[0m, in \u001b[0;36mcreate_compound_cache_from_zenodo\u001b[0;34m(settings)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_compound_cache_from_zenodo\u001b[39m(\n\u001b[1;32m     57\u001b[0m     settings: ZenodoSettings \u001b[38;5;241m=\u001b[39m DEFAULT_COMPOUND_CACHE_SETTINGS,\n\u001b[1;32m     58\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m CompoundCache:\n\u001b[1;32m     59\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;124;03m    Initialize a compound cache from Zenodo.\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     71\u001b[0m \n\u001b[1;32m     72\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     path \u001b[38;5;241m=\u001b[39m \u001b[43mget_cached_filepath\u001b[49m\u001b[43m(\u001b[49m\u001b[43msettings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m create_compound_cache_from_sqlite_file(path)\n",
      "File \u001b[0;32m/opt/conda/envs/myenv/lib/python3.9/site-packages/equilibrator_cache/zenodo.py:195\u001b[0m, in \u001b[0;36mget_cached_filepath\u001b[0;34m(settings)\u001b[0m\n\u001b[1;32m    193\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFetching a new version of the Compound Cache from Zenodo.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 195\u001b[0m     dataframe_dict \u001b[38;5;241m=\u001b[39m \u001b[43mget_zenodo_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43msettings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError:\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\n\u001b[1;32m    198\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSome required data needs to be downloaded from Zenodo.org, but \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    199\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthere is a communication problem at the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    200\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmoment. Please wait and try again later.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    201\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/envs/myenv/lib/python3.9/site-packages/equilibrator_cache/zenodo.py:157\u001b[0m, in \u001b[0;36mget_zenodo_files\u001b[0;34m(settings, timeout)\u001b[0m\n\u001b[1;32m    155\u001b[0m     fnames \u001b[38;5;241m=\u001b[39m [d[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkey\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfiles\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n\u001b[1;32m    156\u001b[0m     urls \u001b[38;5;241m=\u001b[39m [d[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlinks\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfiles\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n\u001b[0;32m--> 157\u001b[0m     data_streams \u001b[38;5;241m=\u001b[39m [download_from_url(client, url) \u001b[38;5;28;01mfor\u001b[39;00m url \u001b[38;5;129;01min\u001b[39;00m urls]\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(fnames, data_streams))\n",
      "File \u001b[0;32m/opt/conda/envs/myenv/lib/python3.9/site-packages/equilibrator_cache/zenodo.py:157\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    155\u001b[0m     fnames \u001b[38;5;241m=\u001b[39m [d[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkey\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfiles\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n\u001b[1;32m    156\u001b[0m     urls \u001b[38;5;241m=\u001b[39m [d[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlinks\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfiles\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n\u001b[0;32m--> 157\u001b[0m     data_streams \u001b[38;5;241m=\u001b[39m [\u001b[43mdownload_from_url\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m url \u001b[38;5;129;01min\u001b[39;00m urls]\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(fnames, data_streams))\n",
      "File \u001b[0;32m/opt/conda/envs/myenv/lib/python3.9/site-packages/tenacity/__init__.py:333\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;129m@_utils\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f)\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped_f\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw):\n\u001b[0;32m--> 333\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/myenv/lib/python3.9/site-packages/tenacity/__init__.py:423\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    420\u001b[0m retry_state \u001b[38;5;241m=\u001b[39m RetryCallState(\n\u001b[1;32m    421\u001b[0m     retry_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, fn\u001b[38;5;241m=\u001b[39mfn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m    422\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 423\u001b[0m     do \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    424\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    425\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/envs/myenv/lib/python3.9/site-packages/tenacity/__init__.py:372\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    370\u001b[0m     retry_exc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry_error_cls(fut)\n\u001b[1;32m    371\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreraise:\n\u001b[0;32m--> 372\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mretry_exc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    373\u001b[0m     six\u001b[38;5;241m.\u001b[39mraise_from(retry_exc, fut\u001b[38;5;241m.\u001b[39mexception())\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwait:\n",
      "File \u001b[0;32m/opt/conda/envs/myenv/lib/python3.9/site-packages/tenacity/__init__.py:189\u001b[0m, in \u001b[0;36mRetryError.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreraise\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    188\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_attempt\u001b[38;5;241m.\u001b[39mfailed:\n\u001b[0;32m--> 189\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlast_attempt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/envs/myenv/lib/python3.9/concurrent/futures/_base.py:439\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    437\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 439\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m/opt/conda/envs/myenv/lib/python3.9/concurrent/futures/_base.py:391\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    390\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 391\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    393\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    394\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/myenv/lib/python3.9/site-packages/tenacity/__init__.py:426\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    424\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    425\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 426\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    427\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:\n\u001b[1;32m    428\u001b[0m         retry_state\u001b[38;5;241m.\u001b[39mset_exception(sys\u001b[38;5;241m.\u001b[39mexc_info())\n",
      "File \u001b[0;32m/opt/conda/envs/myenv/lib/python3.9/site-packages/equilibrator_cache/zenodo.py:131\u001b[0m, in \u001b[0;36mdownload_from_url\u001b[0;34m(client, url)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[1;32m    130\u001b[0m     total \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 131\u001b[0m md5 \u001b[38;5;241m=\u001b[39m \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent-md5\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    133\u001b[0m num_bytes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tqdm(\n\u001b[1;32m    135\u001b[0m     total\u001b[38;5;241m=\u001b[39mtotal, unit_scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, unit_divisor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1024\u001b[39m, unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mB\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    136\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m progress:\n",
      "File \u001b[0;32m/opt/conda/envs/myenv/lib/python3.9/site-packages/httpx/_models.py:230\u001b[0m, in \u001b[0;36mHeaders.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m items:\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(items)\n\u001b[0;32m--> 230\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'content-md5'"
     ]
    }
   ],
   "source": [
    "all_inhibitors = list(map(lambda e: get_inhibitors(s, e, output = 'kegg'), all_enzymes))\n",
    "\n",
    "# flatten lists\n",
    "all_enzymes = [[enzyme]*len(inhibitors) for enzyme, inhibitors in zip(all_enzymes, all_inhibitors)]\n",
    "all_organisms = [[organism]*len(inhibitors) for organism, inhibitors in zip(all_organisms, all_inhibitors)]\n",
    "all_enzymes = sum(all_enzymes,[])\n",
    "all_inhibitors = sum(all_inhibitors,[])\n",
    "all_organisms = sum(all_organisms,[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_inhibitors, all_enzymes, all_organisms = pickle.load(open('inhibitors.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[20:32:53] SMILES Parse Error: duplicated ring closure 0 bonds atom 0 to itself for input: 'C00244'\n",
      "[20:32:54] SMILES Parse Error: syntax error while parsing: D02313\n",
      "[20:32:54] SMILES Parse Error: Failed parsing SMILES 'D02313' for input: 'D02313'\n",
      "[20:32:54] SMILES Parse Error: unclosed ring for input: 'C19935'\n",
      "[20:32:54] SMILES Parse Error: duplicated ring closure 0 bonds atom 0 to itself for input: 'C00004'\n",
      "[20:32:55] SMILES Parse Error: duplicated ring closure 0 bonds atom 0 to itself for input: 'C00177'\n",
      "[20:32:55] SMILES Parse Error: unclosed ring for input: 'C01326'\n",
      "[20:32:55] SMILES Parse Error: duplicated ring closure 0 bonds atom 0 to itself for input: 'C00177'\n",
      "[20:32:55] SMILES Parse Error: unclosed ring for input: 'C01326'\n",
      "[20:32:55] SMILES Parse Error: duplicated ring closure 0 bonds atom 0 to itself for input: 'C00284'\n",
      "[20:32:55] SMILES Parse Error: syntax error while parsing: D00052\n",
      "[20:32:55] SMILES Parse Error: Failed parsing SMILES 'D00052' for input: 'D00052'\n",
      "[20:32:56] SMILES Parse Error: duplicated ring closure 0 bonds atom 0 to itself for input: 'C00007'\n",
      "[20:32:56] SMILES Parse Error: syntax error while parsing: D00003\n",
      "[20:32:56] SMILES Parse Error: Failed parsing SMILES 'D00003' for input: 'D00003'\n",
      "[20:32:56] SMILES Parse Error: unclosed ring for input: 'C19935'\n",
      "[20:32:56] SMILES Parse Error: unclosed ring for input: 'C01417'\n",
      "[20:32:57] SMILES Parse Error: unclosed ring for input: 'C19935'\n",
      "[20:32:57] SMILES Parse Error: duplicated ring closure 0 bonds atom 0 to itself for input: 'C00088'\n",
      "[20:32:57] SMILES Parse Error: duplicated ring closure 0 bonds atom 0 to itself for input: 'C00698'\n",
      "[20:32:57] SMILES Parse Error: unclosed ring for input: 'C01327'\n",
      "[20:32:58] SMILES Parse Error: syntax error while parsing: D02057\n",
      "[20:32:58] SMILES Parse Error: Failed parsing SMILES 'D02057' for input: 'D02057'\n",
      "[20:32:58] SMILES Parse Error: unclosed ring for input: 'C02441'\n",
      "[20:32:58] SMILES Parse Error: unclosed ring for input: 'C19935'\n",
      "[20:32:58] SMILES Parse Error: duplicated ring closure 0 bonds atom 0 to itself for input: 'C00177'\n",
      "[20:32:58] SMILES Parse Error: unclosed ring for input: 'C01326'\n",
      "[20:32:58] SMILES Parse Error: duplicated ring closure 0 bonds atom 0 to itself for input: 'C00036'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request failed: list index out of range\n",
      "Could not get sequence string for enzyme:2.3.3.8 organism: Escherichia colifrom Uniprot. Returning 'None'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[20:32:59] SMILES Parse Error: duplicated ring closure 0 bonds atom 0 to itself for input: 'C00008'\n",
      "[20:32:59] SMILES Parse Error: syntax error while parsing: G11113\n",
      "[20:32:59] SMILES Parse Error: Failed parsing SMILES 'G11113' for input: 'G11113'\n",
      "[20:33:00] SMILES Parse Error: duplicated ring closure 0 bonds atom 0 to itself for input: 'C00154'\n",
      "[20:33:01] SMILES Parse Error: unclosed ring for input: 'C01367'\n",
      "[20:33:01] SMILES Parse Error: duplicated ring closure 0 bonds atom 0 to itself for input: 'C00026'\n",
      "[20:33:01] SMILES Parse Error: duplicated ring closure 0 bonds atom 0 to itself for input: 'C00100'\n",
      "[20:33:02] SMILES Parse Error: duplicated ring closure 0 bonds atom 0 to itself for input: 'C00004'\n",
      "[20:33:02] ERROR: \n",
      "\n",
      "[20:33:02] ERROR: \n",
      "\n",
      "[20:33:02] ERROR: \n",
      "\n",
      "[20:33:02] ERROR: \n",
      "\n",
      "[20:33:02] ERROR: \n",
      "\n",
      "[20:33:02] ERROR: \n",
      "\n",
      "[20:33:02] ERROR: \n",
      "\n",
      "[20:33:02] ERROR: \n",
      "\n",
      "[20:33:02] ERROR: \n",
      "\n",
      "[20:33:02] ERROR: \n",
      "\n",
      "[20:33:02] ERROR: \n",
      "\n",
      "[20:33:02] ERROR: \n",
      "\n",
      "[20:33:02] ERROR: \n",
      "\n",
      "[20:33:02] ERROR: \n",
      "\n",
      "[20:33:02] ERROR: \n",
      "\n",
      "[20:33:02] ERROR: \n",
      "\n",
      "[20:33:02] ERROR: \n",
      "\n",
      "[20:33:02] ERROR: \n",
      "\n",
      "[20:33:02] ERROR: \n",
      "\n",
      "[20:33:02] ERROR: \n",
      "\n",
      "[20:33:02] ERROR: \n",
      "\n",
      "[20:33:02] ERROR: \n",
      "\n",
      "[20:33:02] ERROR: \n",
      "\n",
      "[20:33:02] ERROR: \n",
      "\n",
      "[20:33:02] ERROR: \n",
      "\n",
      "[20:33:02] ERROR: \n",
      "\n",
      "[20:33:02] ERROR: \n",
      "\n",
      "[20:33:02] ERROR: \n",
      "\n",
      "2024-10-23 20:33:03.066476: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /.singularity.d/libs\n",
      "2024-10-23 20:33:03.068283: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2024-10-23 20:33:03.068348: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (n3148): /proc/driver/nvidia/version does not exist\n",
      "2024-10-23 20:33:03.069607: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n",
      "28\n",
      "28\n",
      "28\n"
     ]
    }
   ],
   "source": [
    "from src.kinetic_estimator.estimators import Estimator\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "os.environ['TORCH_HOME'] = '/mmfs1/gscratch/stf/dalba'\n",
    "\n",
    "KMest = Estimator('KM_prediction','Km')\n",
    "kis = KMest.estimate(all_inhibitors, all_enzymes, all_organisms, True)\n",
    "pd.DataFrame.from_dict(kis).to_csv('241023_missing_kis.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
