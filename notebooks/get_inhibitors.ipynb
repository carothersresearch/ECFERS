{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "s = requests.Session() # create session\n",
    "# Post login credentials to session:\n",
    "s.post('https://websvc.biocyc.org/credentials/login/', data={'email':'dalba@uw.edu', 'password':'RNAdevices2024'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from EC to BioCyc Reaction ID\n",
    "EC = '1.1.1.37'\n",
    "r = s.get('https://metacyc.org/META/substring-search?type=NIL&object=EC+'+EC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc = r.text.find('/META/NEW-IMAGE?type=REACTION&object=') # this only finds the first instance, there may be other reactinos associated with this EC...\n",
    "BioCycID = r.text[loc+37:].split('\"')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from BioCyc Reaction ID to  reactions\n",
    "r = s.get('https://websvc.biocyc.org/apixml?fn=enzymes-of-reaction&id=META:{i}&detail=low'.format(i=BioCycID))\n",
    "reactions = [e.find('catalyzes').find('Enzymatic-Reaction').items()[0][1] for e in list(ET.fromstring(r.text))[1:]]\n",
    "\n",
    "# from reactions to inhibitors\n",
    "inhibitors = []\n",
    "inhibitors_smiles = []\n",
    "for reaction in reactions:\n",
    "    r = s.get('https://websvc.biocyc.org/apixml?fn=direct-inhibitors&id={i}&detail=low'.format(i=reaction))\n",
    "    inhibitors.append([list(c)[-1].text for c in list(ET.fromstring(r.text))[1:]])\n",
    "    inhibitors_smiles.append([c.find('cml')[0][-1].text for c in list(ET.fromstring(r.text))[1:]])\n",
    "\n",
    "inhibitors = sum(inhibitors,[])\n",
    "inhibitors_smiles = sum(inhibitors_smiles,[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C(C([O-])=O)C(=O)C([O-])=O',\n",
       " 'C(OP(=O)([O-])OP(=O)([O-])OP(=O)([O-])[O-])[C@H]3(O[C@@H](N1(C2(\\\\C(\\\\N=C/1)=C(N)/N=C\\\\N=2)))[C@H](O)[C@H](O)3)',\n",
       " 'CC(=O)SCCNC(=O)CCNC(=O)[C@H](O)C(C)(C)COP(OP([O-])(OC[C@@H]1([C@@H](OP([O-])([O-])=O)[C@@H](O)[C@@H](O1)N2(C3(\\\\N=C/N=C(C(\\\\N=C/2)=3)/N))))=O)([O-])=O',\n",
       " 'CC(C)(COP([O-])(=O)OP(OC[C@H]3(O[C@@H](N1(C2(\\\\N=C/N=C(C(\\\\N=C/1)=2)/N)))[C@H](O)[C@H](OP([O-])(=O)[O-])3))(=O)[O-])[C@@H](O)C(=O)NCCC(=O)NCCS',\n",
       " 'C([O-])(C(=O)[O-])=O',\n",
       " 'CCN1(C(=O)\\\\C=C/C(=O)1)',\n",
       " 'C2(/C=C(C(/C(=O)[O-])=C\\\\C(\\\\SSC1(\\\\C=C(C(/[N+]([O-])=O)=C\\\\C=1)\\\\C(=O)[O-]))=2)/[N+]([O-])=O)',\n",
       " 'C1(\\\\C=C(\\\\C=C/N=1)\\\\SSC2(\\\\C=C/N=C\\\\C=2))',\n",
       " 'CCOC(OC(OCC)=O)=O',\n",
       " 'CC(C(C)=O)=O',\n",
       " '[Cd+2]']"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inhibitors_smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "from equilibrator_api import ComponentContribution\n",
    "cc = ComponentContribution()\n",
    "\n",
    "inhibitors_kegg = []\n",
    "for inhibitor in inhibitors:\n",
    "    try: # the inhibitor string may be too off, or has no kegg id\n",
    "        for i in cc.search_compound(inhibitor).identifiers:\n",
    "            if i.registry.namespace == 'kegg':\n",
    "                inhibitors_kegg.append(i.accession)\n",
    "    except:\n",
    "        inhibitors_kegg.append('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C00036',\n",
       " 'C00002',\n",
       " 'D08646',\n",
       " 'C00024',\n",
       " 'C00010',\n",
       " 'C00209',\n",
       " 'C02441',\n",
       " 'C11592',\n",
       " 'C00741',\n",
       " '']"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inhibitors_kegg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let put in a function and run thorugh all ECs\n",
    "\n",
    "def get_inhibitors(s, EC, output = 'SMILES'):\n",
    "    try:\n",
    "        with open(os.getcwd()+'/src/kinetic_estimator/biocyc_cache.pickle', 'rb') as handle:\n",
    "            biocyc_cache = pickle.load(handle)\n",
    "    except:\n",
    "        biocyc_cache = {}\n",
    "    \n",
    "    if EC+'_'+output in biocyc_cache:\n",
    "        return biocyc_cache[EC+'_'+output]\n",
    "    \n",
    "    else:\n",
    "        r = s.get('https://metacyc.org/META/substring-search?type=NIL&object=EC+'+EC)\n",
    "        loc = r.text.find('/META/NEW-IMAGE?type=REACTION&object=') # this only finds the first instance, there may be other reactinos associated with this EC...\n",
    "        BioCycID = r.text[loc+37:].split('\"')[0]\n",
    "\n",
    "        # from BioCyc Reaction ID to  reactions\n",
    "        r = s.get('https://websvc.biocyc.org/apixml?fn=enzymes-of-reaction&id=META:{i}&detail=low'.format(i=BioCycID))\n",
    "        if r.status_code != 200:\n",
    "            print('No reaction found for EC '+EC)\n",
    "            return []\n",
    "        reactions = [e.find('catalyzes').find('Enzymatic-Reaction').items()[0][1] for e in list(ET.fromstring(r.text))[1:]]\n",
    "\n",
    "        # from reactions to inhibitors\n",
    "        inhibitors = []\n",
    "        inhibitors_smiles = []\n",
    "        for reaction in reactions:\n",
    "            r = s.get('https://websvc.biocyc.org/apixml?fn=direct-inhibitors&id={i}&detail=low'.format(i=reaction))\n",
    "            inhibitors.append([list(c)[-1].text for c in list(ET.fromstring(r.text))[1:] if c ])\n",
    "            inhibitors_smiles.append([c.find('cml')[0][-1].text for c in list(ET.fromstring(r.text))[1:] if c and c.find('cml')])\n",
    "\n",
    "        inhibitors = sum(inhibitors,[])\n",
    "        inhibitors_smiles = sum(inhibitors_smiles,[])\n",
    "        biocyc_cache[EC+'_SMILES'] = inhibitors_smiles\n",
    "        biocyc_cache[EC+'_names'] = inhibitors\n",
    "        with open(os.getcwd()+'/src/kinetic_estimator/biocyc_cache.pickle', 'wb') as handle:\n",
    "            pickle.dump(biocyc_cache, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "        if output == 'kegg':\n",
    "            from equilibrator_api import ComponentContribution\n",
    "            cc = ComponentContribution()\n",
    "            inhibitors_kegg = []\n",
    "            for inhibitor in inhibitors:\n",
    "                try: # the inhibitor string may be too off, or has no kegg id\n",
    "                    for i in cc.search_compound(inhibitor).identifiers:\n",
    "                        if i.registry.namespace == 'kegg':\n",
    "                            inhibitors_kegg.append(i.accession)\n",
    "                except:\n",
    "                    print(\"Didn't find kegg id for \"+inhibitor)\n",
    "                    # inhibitors_kegg.append('')\n",
    "                    pass\n",
    "            biocyc_cache[EC+'_kegg'] = inhibitors_kegg\n",
    "            with open(os.getcwd()+'/src/kinetic_estimator/biocyc_cache.pickle', 'wb') as handle:\n",
    "                pickle.dump(biocyc_cache, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "            return inhibitors_kegg\n",
    "        \n",
    "        elif output == 'SMILES':\n",
    "            return inhibitors_smiles\n",
    "        elif output == 'names':\n",
    "            return inhibitors\n",
    "        else:\n",
    "            return inhibitors, inhibitors_smiles\n",
    "    \n",
    "# get all EC numbers\n",
    "import gzip\n",
    "import json\n",
    "\n",
    "with gzip.open(\"src/thermo_calculations/kegg_enzymes.json.gz\", \"r\") as f:\n",
    "        ECs = {e['EC']:e['reaction_ids'] for e in json.load(f)}\n",
    "\n",
    "with gzip.open(\"src/thermo_calculations/kegg_reactions.json.gz\", \"r\") as f:\n",
    "        RXNs = {r['RID']:r['reaction'] for r in json.load(f)}\n",
    "\n",
    "reactions = pd.read_csv('src/frenda_brenda/Files/Reaction_full.csv')\n",
    "all_enzymes = []\n",
    "all_organisms = []\n",
    "for i,row in reactions.iterrows():\n",
    "    ec_string = row['EC']\n",
    "    try:\n",
    "        for r in ECs[ec_string]:\n",
    "            try:\n",
    "                if ec_string not in all_enzymes:\n",
    "                    all_enzymes.append(ec_string)\n",
    "                    if type(row['Species']) is str:\n",
    "                        organism = r['Species']\n",
    "                    else:\n",
    "                        organism = 'Escherichia coli' \n",
    "                    all_organisms.append(organism)\n",
    "            except:\n",
    "                pass\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_inhibitors = list(map(lambda e: get_inhibitors(s, e, output = 'kegg'), all_enzymes))\n",
    "\n",
    "# flatten lists\n",
    "all_enzymes = [[enzyme]*len(inhibitors) for enzyme, inhibitors in zip(all_enzymes, all_inhibitors)]\n",
    "all_organisms = [[organism]*len(inhibitors) for organism, inhibitors in zip(all_organisms, all_inhibitors)]\n",
    "all_enzymes = sum(all_enzymes,[])\n",
    "all_inhibitors = sum(all_inhibitors,[])\n",
    "all_organisms = sum(all_organisms,[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[WinError 182] The operating system cannot run %1. Error loading \"c:\\Users\\Diego Alba\\.conda\\envs\\ODBM2\\lib\\site-packages\\torch\\lib\\shm.dll\" or one of its dependencies.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[52], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkinetic_estimator\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mestimators\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Estimator\n\u001b[0;32m      3\u001b[0m KMest \u001b[38;5;241m=\u001b[39m Estimator(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mKM_prediction\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mKm\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m kis \u001b[38;5;241m=\u001b[39m KMest\u001b[38;5;241m.\u001b[39mestimate(all_inhibitors, all_enzymes, all_organisms, \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\Diego Alba\\Documents\\GitHub\\ECFERS\\src\\kinetic_estimator\\estimators.py:5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01moverrides\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EnforceOverrides, overrides, final\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpickle\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkinetic_estimator\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mDLKcat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mDLKcat_model\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkinetic_estimator\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mKM_prediction_function\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetabolite_preprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m metabolite_preprocessing\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkinetic_estimator\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mKM_prediction_function\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mGNN_functions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m calculate_gnn_representations\n",
      "File \u001b[1;32mc:\\Users\\Diego Alba\\Documents\\GitHub\\ECFERS\\src\\kinetic_estimator\\DLKcat\\model.py:11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtimeit\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Diego Alba\\.conda\\envs\\ODBM2\\lib\\site-packages\\torch\\__init__.py:122\u001b[0m\n\u001b[0;32m    120\u001b[0m     err \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mWinError(last_error)\n\u001b[0;32m    121\u001b[0m     err\u001b[38;5;241m.\u001b[39mstrerror \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m Error loading \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdll\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m or one of its dependencies.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     is_loaded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 182] The operating system cannot run %1. Error loading \"c:\\Users\\Diego Alba\\.conda\\envs\\ODBM2\\lib\\site-packages\\torch\\lib\\shm.dll\" or one of its dependencies."
     ]
    }
   ],
   "source": [
    "from src.kinetic_estimator.estimators import Estimator\n",
    "\n",
    "KMest = Estimator('KM_prediction','Km')\n",
    "kis = KMest.estimate(all_inhibitors, all_enzymes, all_organisms, True)\n",
    "pd.DataFrame.from_dict(kis).to_csv('full_report_kis.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ODBM2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
