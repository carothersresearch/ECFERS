{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = 'data/230623_Kinetics_DA/'\n",
    "\n",
    "# get all relevant files: source plates, mixing tables, data\n",
    "buffer_sp = pd.read_excel(data_folder + 'buffers-sp.xlsx', engine='openpyxl').dropna(0,how='all').dropna(1,how='all')\n",
    "plasmid_sp = pd.read_excel(data_folder + 'plasmids_sp.xlsx', engine='openpyxl').dropna(0,how='all').dropna(1,how='all')\n",
    "genex_mt = pd.read_csv(data_folder + 'genex-mt.csv').dropna(0,how='all').dropna(1,how='all')\n",
    "buffers_mt = pd.read_csv(data_folder + 'buffers-mt.csv').dropna(0,how='all').dropna(1,how='all')\n",
    "data = pd.read_excel(data_folder + 'output.xlsx', engine='openpyxl').dropna(0,how='all').dropna(1,how='all')\n",
    "# how do we handle values with no standard curve\n",
    "\n",
    "# get species and reaction columns\n",
    "species_index_b = [addition in buffer_sp.iloc[:,0].values for addition in list(buffers_mt.iloc[0,1:].keys())]\n",
    "reactions_index_b = [addition not in buffer_sp.iloc[:,0].values for addition in list(buffers_mt.iloc[0,1:].keys())]\n",
    "species_index_g = [addition in buffer_sp.iloc[:,0].values for addition in list(genex_mt.iloc[0,1:].keys())]\n",
    "plasmids_index_g = [addition not in buffer_sp.iloc[:,0].values for addition in list(genex_mt.iloc[0,1:].keys())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get standards and parse equations\n",
    "standards = pd.read_excel('data/LCMS_Standards.xlsx', engine='openpyxl').dropna(0,how='all').dropna(1,how='all')\n",
    "\n",
    "# get mesurement columns\n",
    "measurement_index = [np.any([slabel in dlabel for slabel in standards.iloc[:,0].values]) for dlabel in list(data.iloc[0,1:].keys())] # will only recognize label if in standards \n",
    "\n",
    "peak_to_concentration = {}\n",
    "for row in standards.iterrows():\n",
    "    equation = row[1]['Equation']\n",
    "    # Use regular expressions to extract the slope and y-intercept\n",
    "    match_pos = re.search(r'Y = (\\d+)X \\+ (\\d+)', equation.replace('*',''))\n",
    "    match_neg = re.search(r'Y = (\\d+)X \\- (\\d+)', equation.replace('*',''))\n",
    "\n",
    "    if match_pos:\n",
    "        slope = int(match_pos.group(1))\n",
    "        y_intercept = int(match_pos.group(2))\n",
    "\n",
    "    if match_neg:\n",
    "        slope = int(match_neg.group(1))\n",
    "        y_intercept = -int(match_neg.group(2))\n",
    "\n",
    "    peak_to_concentration[row[1]['Metabolite']] = lambda peak_area: (peak_area-y_intercept)/slope # what are the units?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get information for simulation for each sample\n",
    "# assuming the format for kinetic data is the same\n",
    "\n",
    "# average measurements across replicates and convert to concentrations\n",
    "data_entries = []\n",
    "for i in range(len(data)): # for every data point\n",
    "    d = data.iloc[:,1:].iloc[i,measurement_index].groupby(lambda x: x.split('_')[0]).mean().to_dict()\n",
    "    d = {k:peak_to_concentration[k](v) for k,v in d.items()}  \n",
    "    d['sample'] = data['Unnamed: 0'][i]\n",
    "    d['time'] = data['Time'][i]*60*60\n",
    "    data_entries.append(d)\n",
    "data_to_fit = pd.DataFrame(data_entries).set_index('sample')\n",
    "\n",
    "metadata = {}\n",
    "metadata['dilution_factor'] = data.groupby('Unnamed: 0')['Dilution'].apply(lambda x: np.unique(x)[0]).to_dict()\n",
    "metadata['timepoints'] = data_to_fit.groupby('sample')['time'].apply(lambda x: np.sort(x)).to_dict()\n",
    "metadata['measurement_labels'] = list(data_to_fit.columns)[:-1]\n",
    "metadata['sample_labels'] = list(data_to_fit.index.unique())\n",
    "\n",
    "measurements = {}\n",
    "enzyme_concentrations = {}\n",
    "species_concentrations = {}\n",
    "\n",
    "for sample in data.iloc[:,0].unique(): # for every sample name\n",
    "    species = buffers_mt[buffers_mt['Unnamed: 0'] == sample].iloc[:,1:].iloc[0,species_index_b] # get which species were added\n",
    "    reactions = buffers_mt[buffers_mt['Unnamed: 0'] == sample].iloc[:,1:].iloc[0, reactions_index_b] # get which txtl reactions were added\n",
    "    for reaction in reactions.iteritems(): # for every reaction, get which plasmids and cofactors were added\n",
    "        if reaction[1] > 0:\n",
    "            plasmids = genex_mt[genex_mt['Unnamed: 0'] == reaction[0]].iloc[:,1:].iloc[0, plasmids_index_g]\n",
    "            enzyme_concentrations[sample] =  plasmids/plasmids.sum()*reaction[1]/200 # still need to convert to molar based on txtl capacity, and make sure the dilution math is right\n",
    "            # also need to get the cofactors added during genex, dilute them, and add them to the biosyn concentrations. eh, maybe not\n",
    "            # need to fix the labeling across mixing tables (biotin vs Biotin)\n",
    "    species_concentrations[sample] = species # need to make sure they all have the same units, and add any cofactors added during genex\n",
    "    try:\n",
    "        measurements[sample] = data_to_fit.loc[sample].sort_values(by='time').drop(columns='time').to_numpy() # if there is kinetic data\n",
    "    except:\n",
    "        measurements[sample] = data_to_fit.loc[sample][:-1].to_numpy() # if there is just one timepoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to convert all labels into kegg ids and EC numbers for the model\n",
    "\n",
    "# converting species labels to kegg ids can be done with equilibrator_api\n",
    "from equilibrator_api import ComponentContribution\n",
    "cc = ComponentContribution()\n",
    "\n",
    "try:\n",
    "    with open('src/fitting/speciess_kegg.pkl', 'rb') as f:\n",
    "        speciess_kegg = pickle.load(f)\n",
    "except:\n",
    "    speciess_kegg = {}\n",
    "\n",
    "for species in buffer_sp.iloc[:,0].values:\n",
    "    if species not in speciess_kegg.keys():\n",
    "        try: # the inhibitor string may be too off, or has no kegg id\n",
    "            for i in cc.search_compound(species).identifiers:\n",
    "                if i.registry.namespace == 'kegg':\n",
    "                    speciess_kegg[species] = i.accession\n",
    "                    break # if there are multiple kegg ids, just take the first one which is usually C#### instead of D/G####\n",
    "        except:\n",
    "            speciess_kegg[species] = '' # some of these will fail, maybe this is something we run a priori, curate, and then just read a file\n",
    "\n",
    "with open('src/fitting/speciess_kegg.pkl', 'wb') as f:\n",
    "    pickle.dump(speciess_kegg, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enzyme namre to kegg converter -> enzymes_kegg\n",
    "# info to convert enzyme labels to EC should be in the file Maggie inputs to FRENDA-BRENDA (?) \n",
    "# for k,v in enzyme_concentrations.items():\n",
    "#     enzyme_concentrations[k] = v.rename({k:enzymes_kegg[k] for k in v.index})\n",
    "\n",
    "for k,v in species_concentrations.items():\n",
    "    species_concentrations[k] = v.rename({k:speciess_kegg[k] for k in v.index})\n",
    "\n",
    "init_concentrations = {sample:species_concentrations[sample].append(enzyme_concentrations[sample]) for sample in metadata['sample_labels']}\n",
    "\n",
    "metadata['measurement_labels'] = [speciess_kegg[l] for l in metadata['measurement_labels']]\n",
    "\n",
    "simulation_ready = {'init_concentrations':init_concentrations, \n",
    "                    'metadata':metadata,\n",
    "                    'measurements':measurements}\n",
    "\n",
    "with open(data_folder + 'simulation_ready.pkl', 'wb') as f:\n",
    "    pickle.dump(simulation_ready, f, pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ODBM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
